spring.config.import=optional:secrets.properties
server.port=8083

spring.cloud.azure.keyvault.secret.property-source-enabled=true
spring.cloud.azure.keyvault.secret.property-sources[0].credential.client-id=${CLIENT_ID}
spring.cloud.azure.keyvault.secret.property-sources[0].credential.client-secret=${CLIENT_SECRET}
spring.cloud.azure.keyvault.secret.property-sources[0].endpoint=${END_POINT}
spring.cloud.azure.keyvault.secret.property-sources[0].profile.tenant-id=${TENANT_ID}

# Required connection configs for Kafka producer, consumer, and admin
spring.kafka.properties.sasl.mechanism=PLAIN
spring.kafka.properties.bootstrap.servers=${confluent-kafka-server}
spring.kafka.properties.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule   required username='${confluent-kafka-username}'   password='${confluent-kafka-password}';
spring.kafka.properties.security.protocol=SASL_SSL

# Best practice for higher availability in Apache Kafka clients prior to 3.0
spring.kafka.properties.session.timeout.ms=45000

# Required connection configs for Confluent Cloud Schema Registry
spring.kafka.properties.basic.auth.credentials.source=USER_INFO
spring.kafka.properties.basic.auth.user.info={{ SR_API_KEY }}:{{ SR_API_SECRET }}
spring.kafka.properties.schema.registry.url=https://{{ SR_ENDPOINT }}

spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.IntegerSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.IntegerDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer

spring.data.mongodb.uri=${mongodb-user}

auth0.audience=${auth0-audience}
spring.security.oauth2.resourceserver.jwt.issuer-uri=${issuer-uri}